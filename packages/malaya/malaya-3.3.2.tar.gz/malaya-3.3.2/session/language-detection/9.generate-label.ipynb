{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['other', 'malay', 'ind', 'eng'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('formal-language.json') as fopen:\n",
    "    formal = json.load(fopen)\n",
    "    \n",
    "formal.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rojak', 'malay', 'ind'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('social-language.json') as fopen:\n",
    "    social = json.load(fopen)\n",
    "    \n",
    "social.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "912682"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('manglish.json') as fopen:\n",
    "    manglish = json.load(fopen)\n",
    "    \n",
    "len(manglish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mai la',\n",
       " 'power lah even shopback come to edmw riao',\n",
       " 'chiu r welcome',\n",
       " 'cool hor',\n",
       " 'wa chiobu sia',\n",
       " 'however if one were to say it like you wait ah i go csi chiu that s definitely a remark in jest',\n",
       " 'how come the regina kam thread is still around',\n",
       " 'see hor',\n",
       " 'ah tao come out to clear things out',\n",
       " 'wah long tao clear things up']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manglish[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('eng.json') as fopen:\n",
    "    eng = json.load(fopen)\n",
    "    \n",
    "len(eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61182"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('cmn.json') as fopen:\n",
    "    cmn = json.load(fopen)\n",
    "    \n",
    "len(cmn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "for k in formal.keys():\n",
    "    X.extend(formal[k])\n",
    "    Y.extend([k] * len(formal[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in social.keys():\n",
    "    X.extend(social[k])\n",
    "    Y.extend([k] * len(social[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.extend(manglish)\n",
    "Y.extend(['manglish'] * len(manglish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.extend(eng)\n",
    "Y.extend(['eng'] * len(eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.extend(cmn)\n",
    "Y.extend(['other'] * len(cmn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X) == len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11401734/11401734 [00:06<00:00, 1726821.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "actual_X, actual_Y = [], []\n",
    "\n",
    "for i in tqdm(range(len(X))):\n",
    "    if len(X[i]):\n",
    "        actual_X.append(X[i])\n",
    "        actual_Y.append(Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11366066, 11401734)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_X), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(actual_X, actual_Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['eng', 'ind', 'malay', 'manglish', 'other', 'rojak'], dtype='<U8'),\n",
       " array([ 439871, 1416023, 5622954,  730262,  314519,  569223]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_Y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['eng', 'ind', 'malay', 'manglish', 'other', 'rojak'], dtype='<U8'),\n",
       " array([ 110129,  354327, 1405848,  182420,   78259,  142231]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_Y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train-test.json', 'w') as fopen:\n",
    "    json.dump({'train_X': train_X, 'test_X': test_X, 'train_Y': train_Y, 'test_Y': test_Y}, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__rus Ты можешь позвонить Тому и сказать, чтобы он немедленно приезжал?\r\n",
      "__label__rus А рыльце-то у него в пушку.\r\n",
      "__label__ind Sebagaimana kita memerlukan udara yang nyaman, juga ikan memerlukan air yang bersih.\r\n",
      "__label__epo Italio havas du montoĉenojn, Alpojn kaj Apeninojn.\r\n",
      "__label__rus Этот ботинок дерьмовый, потому что он из Китая.\r\n",
      "__label__tur Sami bilgisayarların nasıl hackleneceğini bilmiyor.\r\n",
      "__label__rus Президент остался в постели.\r\n",
      "__label__eng I can't remember anything else about Tom.\r\n",
      "__label__eng It's what I wanted.\r\n",
      "__label__ber Sami yessen yelli-s n yiwen n yimsujji.\r\n"
     ]
    }
   ],
   "source": [
    "!head valid.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9092852/9092852 [00:09<00:00, 924381.01it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "texts = []\n",
    "\n",
    "for i in tqdm(range(len(train_X))):\n",
    "    texts.append('__label__%s %s'%(train_Y[i], train_X[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train-bahasa.txt', 'w') as fopen:\n",
    "    fopen.write('\\n'.join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__malay tgh struggle siapkan report ke tu\r\n",
      "__label__ind sejenis pakaian obat provinsi\r\n",
      "__label__malay yang pasti brand mandiri atau brand bni merupakan brand registered yang tidak boleh dimiliki oleh badan usaha apapu\r\n",
      "__label__malay hehe sabarlah awak sauna kejap\r\n",
      "__label__malay kapan upload foto lagi bang aku rindu udah hari atau setengah bulan atau minggu ga upload ah entahlah int\r\n",
      "__label__manglish cb on mc but my phone kept blowing up in the morning\r\n",
      "__label__malay cungha minum gituan wkwk\r\n",
      "__label__eng sami and layla are talking about homework\r\n",
      "__label__rojak kunjungan hormat mr zhang guanzi timbalan datuk bandar dongguan china ke atas ybhg datuk dr aminuddin hassim p\r\n",
      "__label__malay tujuh tahun kemudian bersatu semula dengan barisan pelakon eiffel i m in love menerusi penggambaran kesinambungan filem tersebut\r\n"
     ]
    }
   ],
   "source": [
    "!head train-bahasa.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
