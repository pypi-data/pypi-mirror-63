{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 个性化推荐\n",
        "\n",
        "本教程源代码目录在[book/recommender_system](https://github.com/PaddlePaddle/book/tree/develop/05.recommender_system),初次使用请您参考[Book文档使用说明](https://github.com/PaddlePaddle/book/blob/develop/README.cn.md#运行这本书)。\n",
        "\n",
        "### 说明: ###\n",
        "1. 硬件环境要求：\n",
        "本文可支持在CPU、GPU下运行\n",
        "2. Docker镜像支持的CUDA/cuDNN版本：\n",
        "如果使用了Docker运行Book，请注意：这里所提供的默认镜像的GPU环境为 CUDA 8/cuDNN 5，对于NVIDIA Tesla V100等要求CUDA 9的 GPU，使用该镜像可能会运行失败。\n",
        "3. 文档和脚本中代码的一致性问题：\n",
        "请注意：为使本文更加易读易用，我们拆分、调整了train.py的代码并放入本文。本文中代码与train.py的运行结果一致，可直接运行[train.py](https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/train.py)进行验证。\n",
        "\n",
        "## 背景介绍\n",
        "\n",
        "在网络技术不断发展和电子商务规模不断扩大的背景下，商品数量和种类快速增长，用户需要花费大量时间才能找到自己想买的商品，这就是信息超载问题。为了解决这个难题，个性化推荐系统（Recommender System）应运而生。\n",
        "\n",
        "个性化推荐系统是信息过滤系统（Information Filtering System）的子集，它可以用在很多领域，如电影、音乐、电商和 Feed 流推荐等。个性化推荐系统通过分析、挖掘用户行为，发现用户的个性化需求与兴趣特点，将用户可能感兴趣的信息或商品推荐给用户。与搜索引擎不同，个性化推荐系统不需要用户准确地描述出自己的需求，而是根据用户的历史行为进行建模，主动提供满足用户兴趣和需求的信息。\n",
        "\n",
        "1994年明尼苏达大学推出的GroupLens系统[[1](#参考文献)]一般被认为是个性化推荐系统成为一个相对独立的研究方向的标志。该系统首次提出了基于协同过滤来完成推荐任务的思想，此后，基于该模型的协同过滤推荐引领了个性化推荐系统十几年的发展方向。\n",
        "\n",
        "传统的个性化推荐系统方法主要有：\n",
        "\n",
        "- 协同过滤推荐（Collaborative Filtering Recommendation）：该方法是应用最广泛的技术之一，需要收集和分析用户的历史行为、活动和偏好。它通常可以分为两个子类：基于用户 （User-Based）的推荐[[1](#参考文献)] 和基于物品（Item-Based）的推荐[[2](#参考文献)]。该方法的一个关键优势是它不依赖于机器去分析物品的内容特征，因此它无需理解物品本身也能够准确地推荐诸如电影之类的复杂物品；缺点是对于没有任何行为的新用户存在冷启动的问题，同时也存在用户与商品之间的交互数据不够多造成的稀疏问题。值得一提的是，社交网络[[3](#参考文献)]或地理位置等上下文信息都可以结合到协同过滤中去。\n",
        "- 基于内容过滤推荐[[4](#参考文献)]（Content-based Filtering Recommendation）：该方法利用商品的内容描述，抽象出有意义的特征，通过计算用户的兴趣和商品描述之间的相似度，来给用户做推荐。优点是简单直接，不需要依据其他用户对商品的评价，而是通过商品属性进行商品相似度度量，从而推荐给用户所感兴趣商品的相似商品；缺点是对于没有任何行为的新用户同样存在冷启动的问题。\n",
        "- 组合推荐[[5](#参考文献)]（Hybrid Recommendation）：运用不同的输入和技术共同进行推荐，以弥补各自推荐技术的缺点。\n",
        "\n",
        "近些年来，深度学习在很多领域都取得了巨大的成功。学术界和工业界都在尝试将深度学习应用于个性化推荐系统领域中。深度学习具有优秀的自动提取特征的能力，能够学习多层次的抽象特征表示，并对异质或跨域的内容信息进行学习，可以一定程度上处理个性化推荐系统冷启动问题[[6](#参考文献)]。本教程主要介绍个性化推荐的深度学习模型，以及如何使用PaddlePaddle实现模型。\n",
        "\n",
        "## 效果展示\n",
        "\n",
        "我们使用包含用户信息、电影信息与电影评分的数据集作为个性化推荐的应用场景。当我们训练好模型后，只需要输入对应的用户ID和电影ID，就可以得出一个匹配的分数（范围[0,5]，分数越高视为兴趣越大），然后根据所有电影的推荐得分排序，推荐给用户可能感兴趣的电影。\n",
        "\n",
        "```\n",
        "Input movie_id: 1962\n",
        "Input user_id: 1\n",
        "Prediction Score is 4.25\n",
        "```\n",
        "\n",
        "## 模型概览\n",
        "\n",
        "本章中，我们首先介绍YouTube的视频个性化推荐系统[[7](#参考文献)]，然后介绍我们实现的融合推荐模型。\n",
        "\n",
        "### YouTube的深度神经网络个性化推荐系统\n",
        "\n",
        "YouTube是世界上最大的视频上传、分享和发现网站，YouTube个性化推荐系统为超过10亿用户从不断增长的视频库中推荐个性化的内容。整个系统由两个神经网络组成：候选生成网络和排序网络。候选生成网络从百万量级的视频库中生成上百个候选，排序网络对候选进行打分排序，输出排名最高的数十个结果。系统结构如图1所示：\n",
        "\n",
        "\u003cp align=\"center\"\u003e\n",
        "\u003cimg src=\"https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/image/YouTube_Overview.png?raw=true\" width=\"70%\" \u003e\u003cbr/\u003e\n",
        "图1. YouTube 个性化推荐系统结构\n",
        "\u003c/p\u003e\n",
        "\n",
        "#### 候选生成网络（Candidate Generation Network）\n",
        "\n",
        "候选生成网络将推荐问题建模为一个类别数极大的多类分类问题：对于一个Youtube用户，使用其观看历史（视频ID）、搜索词记录（search tokens）、人口学信息（如地理位置、用户登录设备）、二值特征（如性别，是否登录）和连续特征（如用户年龄）等，对视频库中所有视频进行多分类，得到每一类别的分类结果（即每一个视频的推荐概率），最终输出概率较高的几百个视频。\n",
        "\n",
        "首先，将观看历史及搜索词记录这类历史信息，映射为向量后取平均值得到定长表示；同时，输入人口学特征以优化新用户的推荐效果，并将二值特征和连续特征归一化处理到[0, 1]范围。接下来，将所有特征表示拼接为一个向量，并输入给非线形多层感知器（MLP，详见[识别数字](https://github.com/PaddlePaddle/book/blob/develop/02.recognize_digits/README.cn.md)教程）处理。最后，训练时将MLP的输出给softmax做分类，预测时计算用户的综合特征（MLP的输出）与所有视频的相似度，取得分最高的$k$个作为候选生成网络的筛选结果。图2显示了候选生成网络结构。\n",
        "\n",
        "\u003cp align=\"center\"\u003e\n",
        "\u003cimg src=\"https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/image/Deep_candidate_generation_model_architecture.png?raw=true\" width=\"70%\" \u003e\u003cbr/\u003e\n",
        "图2. 候选生成网络结构\n",
        "\u003c/p\u003e\n",
        "\n",
        "对于一个用户$U$，预测此刻用户要观看的视频$\\omega$为视频$i$的概率公式为：\n",
        "\n",
        "\u003cp align=\"center\"\u003e\n",
        "\u003cimg src=\"https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/image/formula1.png?raw=true\" width=\"20%\" \u003e\u003cbr/\u003e\n",
        "\u003c/p\u003e\n",
        "\n",
        "其中$u$为用户$U$的特征表示，$V$为视频库集合，$v_i$为视频库中第$i$个视频的特征表示。$u$和$v_i$为长度相等的向量，两者点积可以通过全连接层实现。\n",
        "\n",
        "考虑到softmax分类的类别数非常多，为了保证一定的计算效率：1）训练阶段，使用负样本类别采样将实际计算的类别数缩小至数千；2）推荐（预测）阶段，忽略softmax的归一化计算（不影响结果），将类别打分问题简化为点积（dot product）空间中的最近邻（nearest neighbor）搜索问题，取与$u$最近的$k$个视频作为生成的候选。\n",
        "\n",
        "#### 排序网络（Ranking Network）\n",
        "排序网络的结构类似于候选生成网络，但是它的目标是对候选进行更细致的打分排序。和传统广告排序中的特征抽取方法类似，这里也构造了大量的用于视频排序的相关特征（如视频 ID、上次观看时间等）。这些特征的处理方式和候选生成网络类似，不同之处是排序网络的顶部是一个加权逻辑回归（weighted logistic regression），它对所有候选视频进行打分，从高到底排序后将分数较高的一些视频返回给用户。\n",
        "\n",
        "### 融合推荐模型\n",
        "本节会使用卷积神经网络（Convolutional Neural Networks）来学习电影名称的表示。下面会依次介绍文本卷积神经网络以及融合推荐模型。\n",
        "\n",
        "#### 文本卷积神经网络（CNN）\n",
        "\n",
        "卷积神经网络经常用来处理具有类似网格拓扑结构（grid-like topology）的数据。例如，图像可以视为二维网格的像素点，自然语言可以视为一维的词序列。卷积神经网络可以提取多种局部特征，并对其进行组合抽象得到更高级的特征表示。实验表明，卷积神经网络能高效地对图像及文本问题进行建模处理。\n",
        "\n",
        "卷积神经网络主要由卷积（convolution）和池化（pooling）操作构成，其应用及组合方式灵活多变，种类繁多。本小结我们以如图3所示的网络进行讲解：\n",
        "\n",
        "\u003cp align=\"center\"\u003e\n",
        "\u003cimg src=\"https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/image/text_cnn.png?raw=true\" width = \"80%\" align=\"center\"/\u003e\u003cbr/\u003e\n",
        "图3. 卷积神经网络文本分类模型\n",
        "\u003c/p\u003e\n",
        "\n",
        "假设待处理句子的长度为$n$，其中第$i$个词的词向量为$x_i\\in\\mathbb{R}^k$，$k$为维度大小。\n",
        "\n",
        "首先，进行词向量的拼接操作：将每$h$个词拼接起来形成一个大小为$h$的词窗口，记为$x_{i:i+h-1}$，它表示词序列$x_{i},x_{i+1},\\ldots,x_{i+h-1}$的拼接，其中，$i$表示词窗口中第一个词在整个句子中的位置，取值范围从$1$到$n-h+1$，$x_{i:i+h-1}\\in\\mathbb{R}^{hk}$。\n",
        "\n",
        "其次，进行卷积操作：把卷积核(kernel)$w\\in\\mathbb{R}^{hk}$应用于包含$h$个词的窗口$x_{i:i+h-1}$，得到特征$c_i=f(w\\cdot x_{i:i+h-1}+b)$，其中$b\\in\\mathbb{R}$为偏置项（bias），$f$为非线性激活函数，如$sigmoid$。将卷积核应用于句子中所有的词窗口${x_{1:h},x_{2:h+1},\\ldots,x_{n-h+1:n}}$，产生一个特征图（feature map）：\n",
        "\n",
        "\u003cp align=\"center\"\u003e\n",
        "\u003cimg src=\"https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/image/formula2.png?raw=true\" width=\"40%\" \u003e\u003cbr/\u003e\n",
        "\u003c/p\u003e\n",
        "\n",
        "接下来，对特征图采用时间维度上的最大池化（max pooling over time）操作得到此卷积核对应的整句话的特征$\\hat c$，它是特征图中所有元素的最大值：\n",
        "\n",
        "\u003cp align=\"center\"\u003e\n",
        "\u003cimg src=\"https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/image/formula3.png?raw=true\" width=\"15%\" \u003e\u003cbr/\u003e\n",
        "\u003c/p\u003e\n",
        "\n",
        "#### 融合推荐模型概览\n",
        "\n",
        "在融合推荐模型的电影个性化推荐系统中：\n",
        "\n",
        "1. 首先，使用用户特征和电影特征作为神经网络的输入，其中：\n",
        "\n",
        "   - 用户特征融合了四个属性信息，分别是用户ID、性别、职业和年龄。\n",
        "\n",
        "   - 电影特征融合了三个属性信息，分别是电影ID、电影类型ID和电影名称。\n",
        "\n",
        "2. 对用户特征，将用户ID映射为维度大小为256的向量表示，输入全连接层，并对其他三个属性也做类似的处理。然后将四个属性的特征表示分别全连接并相加。\n",
        "\n",
        "3. 对电影特征，将电影ID以类似用户ID的方式进行处理，电影类型ID以向量的形式直接输入全连接层，电影名称用文本卷积神经网络得到其定长向量表示。然后将三个属性的特征表示分别全连接并相加。\n",
        "\n",
        "4. 得到用户和电影的向量表示后，计算二者的余弦相似度作为个性化推荐系统的打分。最后，用该相似度打分和用户真实打分的差异的平方作为该回归模型的损失函数。\n",
        "\n",
        "\u003cp align=\"center\"\u003e\n",
        "\u003cimg src=\"https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/image/rec_regression_network.png?raw=true\" width=\"90%\" \u003e\u003cbr/\u003e\n",
        "图4. 融合推荐模型\n",
        "\u003c/p\u003e\n",
        "\n",
        "## 数据准备\n",
        "\n",
        "### 数据介绍与下载\n",
        "\n",
        "我们以 [MovieLens 百万数据集（ml-1m）](http://files.grouplens.org/datasets/movielens/ml-1m.zip)为例进行介绍。ml-1m 数据集包含了 6,000 位用户对 4,000 部电影的 1,000,000 条评价（评分范围 1~5 分，均为整数），由 GroupLens Research 实验室搜集整理。\n",
        "\n",
        "Paddle在API中提供了自动加载数据的模块。数据模块为 `paddle.dataset.movielens`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from __future__ import print_function\n",
        "import paddle\n",
        "movie_info = paddle.dataset.movielens.movie_info()\n",
        "print(list(movie_info.values())[0])\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "# Run this block to show dataset's documentation\n",
        "# help(paddle.dataset.movielens)\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "在原始数据中包含电影的特征数据，用户的特征数据，和用户对电影的评分。\n",
        "\n",
        "例如，其中某一个电影特征为:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "movie_info = paddle.dataset.movielens.movie_info()\n",
        "print(list(movie_info.values())[0])\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    \u003cMovieInfo id(1), title(Toy Story ), categories(['Animation', \"Children's\", 'Comedy'])\u003e\n",
        "\n",
        "\n",
        "这表示，电影的id是1，标题是《Toy Story》，该电影被分为到三个类别中。这三个类别是动画，儿童，喜剧。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "user_info = paddle.dataset.movielens.user_info()\n",
        "print(list(user_info.values())[0])\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    \u003cUserInfo id(1), gender(F), age(1), job(10)\u003e\n",
        "\n",
        "\n",
        "这表示，该用户ID是1，女性，年龄比18岁还年轻。职业ID是10。\n",
        "\n",
        "\n",
        "其中，年龄使用下列分布\n",
        "\n",
        "*  1:  \"Under 18\"\n",
        "* 18:  \"18-24\"\n",
        "* 25:  \"25-34\"\n",
        "* 35:  \"35-44\"\n",
        "* 45:  \"45-49\"\n",
        "* 50:  \"50-55\"\n",
        "* 56:  \"56+\"\n",
        "\n",
        "职业是从下面几种选项里面选则得出:\n",
        "\n",
        "*  0:  \"other\" or not specified\n",
        "*  1:  \"academic/educator\"\n",
        "*  2:  \"artist\"\n",
        "*  3:  \"clerical/admin\"\n",
        "*  4:  \"college/grad student\"\n",
        "*  5:  \"customer service\"\n",
        "*  6:  \"doctor/health care\"\n",
        "*  7:  \"executive/managerial\"\n",
        "*  8:  \"farmer\"\n",
        "*  9:  \"homemaker\"\n",
        "* 10:  \"K-12 student\"\n",
        "* 11:  \"lawyer\"\n",
        "* 12:  \"programmer\"\n",
        "* 13:  \"retired\"\n",
        "* 14:  \"sales/marketing\"\n",
        "* 15:  \"scientist\"\n",
        "* 16:  \"self-employed\"\n",
        "* 17:  \"technician/engineer\"\n",
        "* 18:  \"tradesman/craftsman\"\n",
        "* 19:  \"unemployed\"\n",
        "* 20:  \"writer\"\n",
        "\n",
        "而对于每一条训练/测试数据，均为 \u003c用户特征\u003e + \u003c电影特征\u003e + 评分。\n",
        "\n",
        "例如，我们获得第一条训练数据:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "train_set_creator = paddle.dataset.movielens.train()\n",
        "train_sample = next(train_set_creator())\n",
        "uid = train_sample[0]\n",
        "mov_id = train_sample[len(user_info[uid].value())]\n",
        "print (\"User %s rates Movie %s with Score %s\"%(user_info[uid], movie_info[mov_id], train_sample[-1]))\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    User \u003cUserInfo id(1), gender(F), age(1), job(10)\u003e rates Movie \u003cMovieInfo id(1193), title(One Flew Over the Cuckoo's Nest ), categories(['Drama'])\u003e with Score [5.0]\n",
        "\n",
        "\n",
        "即用户1对电影1193的评价为5分。\n",
        "\n",
        "## 模型配置说明\n",
        "\n",
        "下面我们开始根据输入数据的形式配置模型。首先引入所需的库函数以及定义全局变量。\n",
        "- IS_SPARSE: embedding中是否使用稀疏更新\n",
        "- PASS_NUM: epoch数量\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "import math\n",
        "import sys\n",
        "import numpy as np\n",
        "import paddle\n",
        "import paddle.fluid as fluid\n",
        "import paddle.fluid.layers as layers\n",
        "import paddle.fluid.nets as nets\n",
        "\n",
        "IS_SPARSE = True\n",
        "BATCH_SIZE = 256\n",
        "PASS_NUM = 20\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "然后为我们的用户特征综合模型定义模型配置\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "def get_usr_combined_features():\n",
        "    \"\"\"network definition for user part\"\"\"\n",
        "\n",
        "    USR_DICT_SIZE = paddle.dataset.movielens.max_user_id() + 1\n",
        "\n",
        "    uid = layers.data(name='user_id', shape=[1], dtype='int64')\n",
        "\n",
        "    usr_emb = layers.embedding(\n",
        "        input=uid,\n",
        "        dtype='float32',\n",
        "        size=[USR_DICT_SIZE, 32],\n",
        "        param_attr='user_table',\n",
        "        is_sparse=IS_SPARSE)\n",
        "\n",
        "    usr_fc = layers.fc(input=usr_emb, size=32)\n",
        "\n",
        "    USR_GENDER_DICT_SIZE = 2\n",
        "\n",
        "    usr_gender_id = layers.data(name='gender_id', shape=[1], dtype='int64')\n",
        "\n",
        "    usr_gender_emb = layers.embedding(\n",
        "        input=usr_gender_id,\n",
        "        size=[USR_GENDER_DICT_SIZE, 16],\n",
        "        param_attr='gender_table',\n",
        "        is_sparse=IS_SPARSE)\n",
        "\n",
        "    usr_gender_fc = layers.fc(input=usr_gender_emb, size=16)\n",
        "\n",
        "    USR_AGE_DICT_SIZE = len(paddle.dataset.movielens.age_table)\n",
        "    usr_age_id = layers.data(name='age_id', shape=[1], dtype=\"int64\")\n",
        "\n",
        "    usr_age_emb = layers.embedding(\n",
        "        input=usr_age_id,\n",
        "        size=[USR_AGE_DICT_SIZE, 16],\n",
        "        is_sparse=IS_SPARSE,\n",
        "        param_attr='age_table')\n",
        "\n",
        "    usr_age_fc = layers.fc(input=usr_age_emb, size=16)\n",
        "\n",
        "    USR_JOB_DICT_SIZE = paddle.dataset.movielens.max_job_id() + 1\n",
        "    usr_job_id = layers.data(name='job_id', shape=[1], dtype=\"int64\")\n",
        "\n",
        "    usr_job_emb = layers.embedding(\n",
        "        input=usr_job_id,\n",
        "        size=[USR_JOB_DICT_SIZE, 16],\n",
        "        param_attr='job_table',\n",
        "        is_sparse=IS_SPARSE)\n",
        "\n",
        "    usr_job_fc = layers.fc(input=usr_job_emb, size=16)\n",
        "\n",
        "    concat_embed = layers.concat(\n",
        "        input=[usr_fc, usr_gender_fc, usr_age_fc, usr_job_fc], axis=1)\n",
        "\n",
        "    usr_combined_features = layers.fc(input=concat_embed, size=200, act=\"tanh\")\n",
        "\n",
        "    return usr_combined_features\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "如上述代码所示，对于每个用户，我们输入4维特征。其中包括user_id,gender_id,age_id,job_id。这几维特征均是简单的整数值。为了后续神经网络处理这些特征方便，我们借鉴NLP中的语言模型，将这几维离散的整数值，变换成embedding取出。分别形成usr_emb, usr_gender_emb, usr_age_emb, usr_job_emb。\n",
        "\n",
        "然后，我们对于所有的用户特征，均输入到一个全连接层(fc)中。将所有特征融合为一个200维度的特征。\n",
        "\n",
        "进而，我们对每一个电影特征做类似的变换，网络配置为:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "def get_mov_combined_features():\n",
        "    \"\"\"network definition for item(movie) part\"\"\"\n",
        "\n",
        "    MOV_DICT_SIZE = paddle.dataset.movielens.max_movie_id() + 1\n",
        "\n",
        "    mov_id = layers.data(name='movie_id', shape=[1], dtype='int64')\n",
        "\n",
        "    mov_emb = layers.embedding(\n",
        "        input=mov_id,\n",
        "        dtype='float32',\n",
        "        size=[MOV_DICT_SIZE, 32],\n",
        "        param_attr='movie_table',\n",
        "        is_sparse=IS_SPARSE)\n",
        "\n",
        "    mov_fc = layers.fc(input=mov_emb, size=32)\n",
        "\n",
        "    CATEGORY_DICT_SIZE = len(paddle.dataset.movielens.movie_categories())\n",
        "\n",
        "    category_id = layers.data(\n",
        "        name='category_id', shape=[1], dtype='int64', lod_level=1)\n",
        "\n",
        "    mov_categories_emb = layers.embedding(\n",
        "        input=category_id, size=[CATEGORY_DICT_SIZE, 32], is_sparse=IS_SPARSE)\n",
        "\n",
        "    mov_categories_hidden = layers.sequence_pool(\n",
        "        input=mov_categories_emb, pool_type=\"sum\")\n",
        "\n",
        "    MOV_TITLE_DICT_SIZE = len(paddle.dataset.movielens.get_movie_title_dict())\n",
        "\n",
        "    mov_title_id = layers.data(\n",
        "        name='movie_title', shape=[1], dtype='int64', lod_level=1)\n",
        "\n",
        "    mov_title_emb = layers.embedding(\n",
        "        input=mov_title_id, size=[MOV_TITLE_DICT_SIZE, 32], is_sparse=IS_SPARSE)\n",
        "\n",
        "    mov_title_conv = nets.sequence_conv_pool(\n",
        "        input=mov_title_emb,\n",
        "        num_filters=32,\n",
        "        filter_size=3,\n",
        "        act=\"tanh\",\n",
        "        pool_type=\"sum\")\n",
        "\n",
        "    concat_embed = layers.concat(\n",
        "        input=[mov_fc, mov_categories_hidden, mov_title_conv], axis=1)\n",
        "\n",
        "    mov_combined_features = layers.fc(input=concat_embed, size=200, act=\"tanh\")\n",
        "\n",
        "    return mov_combined_features\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "电影标题名称(title)是一个序列的整数，整数代表的是这个词在索引序列中的下标。这个序列会被送入 `sequence_conv_pool` 层，这个层会在时间维度上使用卷积和池化。因为如此，所以输出会是固定长度，尽管输入的序列长度各不相同。\n",
        "\n",
        "最后，我们定义一个`inference_program`来使用余弦相似度计算用户特征与电影特征的相似性。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "def inference_program():\n",
        "    \"\"\"the combined network\"\"\"\n",
        "\n",
        "    usr_combined_features = get_usr_combined_features()\n",
        "    mov_combined_features = get_mov_combined_features()\n",
        "\n",
        "    inference = layers.cos_sim(X=usr_combined_features, Y=mov_combined_features)\n",
        "    scale_infer = layers.scale(x=inference, scale=5.0)\n",
        "\n",
        "    return scale_infer\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "进而，我们定义一个`train_program`来使用`inference_program`计算出的结果，在标记数据的帮助下来计算误差。我们还定义了一个`optimizer_func`来定义优化器。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "def train_program():\n",
        "    \"\"\"define the cost function\"\"\"\n",
        "\n",
        "    scale_infer = inference_program()\n",
        "\n",
        "    label = layers.data(name='score', shape=[1], dtype='float32')\n",
        "    square_cost = layers.square_error_cost(input=scale_infer, label=label)\n",
        "    avg_cost = layers.mean(square_cost)\n",
        "\n",
        "    return [avg_cost, scale_infer]\n",
        "\n",
        "\n",
        "def optimizer_func():\n",
        "    return fluid.optimizer.SGD(learning_rate=0.2)\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "## 训练模型\n",
        "\n",
        "### 定义训练环境\n",
        "定义您的训练环境，可以指定训练是发生在CPU还是GPU上。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "use_cuda = False\n",
        "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 定义数据提供器\n",
        "下一步是为训练和测试定义数据提供器。提供器读入一个大小为 `BATCH_SIZE`的数据。`paddle.dataset.movielens.train` 每次会在乱序化后提供一个大小为`BATCH_SIZE`的数据，乱序化的大小为缓存大小`buf_size`。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "train_reader = paddle.batch(\n",
        "    paddle.reader.shuffle(\n",
        "        paddle.dataset.movielens.train(), buf_size=8192),\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "test_reader = paddle.batch(\n",
        "    paddle.dataset.movielens.test(), batch_size=BATCH_SIZE)\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 构造训练过程(trainer)\n",
        "我们这里构造了一个训练过程，包括训练优化函数。\n",
        "\n",
        "### 提供数据\n",
        "\n",
        "`feed_order`用来定义每条产生的数据和`paddle.layer.data`之间的映射关系。比如，`movielens.train`产生的第一列的数据对应的是`user_id`这个特征。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "feed_order = [\n",
        "    'user_id', 'gender_id', 'age_id', 'job_id', 'movie_id', 'category_id',\n",
        "    'movie_title', 'score'\n",
        "]\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 构建训练程序以及测试程序\n",
        "分别构建训练程序和测试程序，并引入训练优化器。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "main_program = fluid.default_main_program()\n",
        "star_program = fluid.default_startup_program()\n",
        "[avg_cost, scale_infer] = train_program()\n",
        "\n",
        "test_program = main_program.clone(for_test=True)\n",
        "sgd_optimizer = optimizer_func()\n",
        "sgd_optimizer.minimize(avg_cost)\n",
        "exe = fluid.Executor(place)\n",
        "\n",
        "def train_test(program, reader):\n",
        "    count = 0\n",
        "    feed_var_list = [\n",
        "        program.global_block().var(var_name) for var_name in feed_order\n",
        "    ]\n",
        "    feeder_test = fluid.DataFeeder(\n",
        "    feed_list=feed_var_list, place=place)\n",
        "    test_exe = fluid.Executor(place)\n",
        "    accumulated = 0\n",
        "    for test_data in reader():\n",
        "        avg_cost_np = test_exe.run(program=program,\n",
        "                                               feed=feeder_test.feed(test_data),\n",
        "                                               fetch_list=[avg_cost])\n",
        "        accumulated += avg_cost_np[0]\n",
        "        count += 1\n",
        "    return accumulated / count\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 构建训练主循环并开始训练\n",
        "我们根据上面定义的训练循环数（`PASS_NUM`）和一些别的参数，来进行训练循环，并且每次循环都进行一次测试，当测试结果足够好时退出训练并保存训练好的参数。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "# Specify the directory path to save the parameters\n",
        "params_dirname = \"recommender_system.inference.model\"\n",
        "\n",
        "from paddle.utils.plot import Ploter\n",
        "train_prompt = \"Train cost\"\n",
        "test_prompt = \"Test cost\"\n",
        "\n",
        "plot_cost = Ploter(train_prompt, test_prompt)\n",
        "\n",
        "def train_loop():\n",
        "    feed_list = [\n",
        "        main_program.global_block().var(var_name) for var_name in feed_order\n",
        "    ]\n",
        "    feeder = fluid.DataFeeder(feed_list, place)\n",
        "    exe.run(star_program)\n",
        "\n",
        "    for pass_id in range(PASS_NUM):\n",
        "        for batch_id, data in enumerate(train_reader()):\n",
        "            # train a mini-batch\n",
        "            outs = exe.run(program=main_program,\n",
        "                               feed=feeder.feed(data),\n",
        "                               fetch_list=[avg_cost])\n",
        "            out = np.array(outs[0])\n",
        "\n",
        "            # get test avg_cost\n",
        "            test_avg_cost = train_test(test_program, test_reader)\n",
        "\n",
        "            plot_cost.append(train_prompt, batch_id, outs[0])\n",
        "            plot_cost.append(test_prompt, batch_id, test_avg_cost)\n",
        "            plot_cost.plot()\n",
        "\n",
        "            if batch_id == 20:\n",
        "                if params_dirname is not None:\n",
        "                    fluid.io.save_inference_model(params_dirname, [\n",
        "                                \"user_id\", \"gender_id\", \"age_id\", \"job_id\",\n",
        "                                \"movie_id\", \"category_id\", \"movie_title\"\n",
        "                        ], [scale_infer], exe)\n",
        "                return\n",
        "            print('EpochID {0}, BatchID {1}, Test Loss {2:0.2}'.format(\n",
        "                            pass_id + 1, batch_id + 1, float(test_avg_cost)))\n",
        "\n",
        "            if math.isnan(float(out[0])):\n",
        "                sys.exit(\"got NaN loss, training failed.\")\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "开始训练\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "train_loop()\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 应用模型\n",
        "\n",
        "### 生成测试数据\n",
        "使用 create_lod_tensor(data, lod, place) 的API来生成细节层次的张量。`data`是一个序列，每个元素是一个索引号的序列。`lod`是细节层次的信息，对应于`data`。比如，data = [[10, 2, 3], [2, 3]] 意味着它包含两个序列，长度分别是3和2。于是相应地 lod = [[3, 2]]，它表明其包含一层细节信息，意味着 `data` 有两个序列，长度分别是3和2。\n",
        "\n",
        "在这个预测例子中，我们试着预测用户ID为1的用户对于电影'Hunchback of Notre Dame'的评分\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "infer_movie_id = 783\n",
        "infer_movie_name = paddle.dataset.movielens.movie_info()[infer_movie_id].title\n",
        "user_id = fluid.create_lod_tensor([[np.int64(1)]], [[1]], place)\n",
        "gender_id = fluid.create_lod_tensor([[np.int64(1)]], [[1]], place)\n",
        "age_id = fluid.create_lod_tensor([[np.int64(0)]], [[1]], place)\n",
        "job_id = fluid.create_lod_tensor([[np.int64(10)]], [[1]], place)\n",
        "movie_id = fluid.create_lod_tensor([[np.int64(783)]], [[1]], place) # Hunchback of Notre Dame\n",
        "category_id = fluid.create_lod_tensor([np.array([10, 8, 9], dtype='int64')], [[3]], place) # Animation, Children's, Musical\n",
        "movie_title = fluid.create_lod_tensor([np.array([1069, 4140, 2923, 710, 988], dtype='int64')], [[5]],\n",
        "                                      place) # 'hunchback','of','notre','dame','the'\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 构建预测过程并测试\n",
        "与训练过程类似，我们需要构建一个预测过程。其中， `params_dirname`是之前用来存放训练过程中的各个参数的地址。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
        "exe = fluid.Executor(place)\n",
        "\n",
        "inference_scope = fluid.core.Scope()\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 测试\n",
        "现在我们可以进行预测了。我们要提供的`feed_order`应该和训练过程一致。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "with fluid.scope_guard(inference_scope):\n",
        "    [inferencer, feed_target_names,\n",
        "    fetch_targets] = fluid.io.load_inference_model(params_dirname, exe)\n",
        "\n",
        "    results = exe.run(inferencer,\n",
        "                          feed={\n",
        "                               'user_id': user_id,\n",
        "                              'gender_id': gender_id,\n",
        "                              'age_id': age_id,\n",
        "                              'job_id': job_id,\n",
        "                              'movie_id': movie_id,\n",
        "                              'category_id': category_id,\n",
        "                              'movie_title': movie_title\n",
        "                          },\n",
        "                          fetch_list=fetch_targets,\n",
        "                          return_numpy=False)\n",
        "    predict_rating = np.array(results[0])\n",
        "    print(\"Predict Rating of user id 1 on movie \\\"\" + infer_movie_name +\n",
        "              \"\\\" is \" + str(predict_rating[0][0]))\n",
        "    print(\"Actual Rating of user id 1 on movie \\\"\" + infer_movie_name +\n",
        "              \"\\\" is 4.\")\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 总结\n",
        "\n",
        "本章介绍了传统的个性化推荐系统方法和YouTube的深度神经网络个性化推荐系统，并以电影推荐为例，使用PaddlePaddle训练了一个个性化推荐神经网络模型。个性化推荐系统几乎涵盖了电商系统、社交网络、广告推荐、搜索引擎等领域的方方面面，而在图像处理、自然语言处理等领域已经发挥重要作用的深度学习技术，也将会在个性化推荐系统领域大放异彩。\n",
        "\n",
        "\u003ca name=\"参考文献\"\u003e\u003c/a\u003e\n",
        "## 参考文献\n",
        "\n",
        "1. P. Resnick, N. Iacovou, etc. “[GroupLens: An Open Architecture for Collaborative Filtering of Netnews](http://ccs.mit.edu/papers/CCSWP165.html)”, Proceedings of ACM Conference on Computer Supported Cooperative Work, CSCW 1994. pp.175-186.\n",
        "2. Sarwar, Badrul, et al. \"[Item-based collaborative filtering recommendation algorithms.](http://files.grouplens.org/papers/www10_sarwar.pdf)\" *Proceedings of the 10th international conference on World Wide Web*. ACM, 2001.\n",
        "3. Kautz, Henry, Bart Selman, and Mehul Shah. \"[Referral Web: combining social networks and collaborative filtering.](http://www.cs.cornell.edu/selman/papers/pdf/97.cacm.refweb.pdf)\" Communications of the ACM 40.3 (1997): 63-65. APA\n",
        "4. [Peter Brusilovsky](https://en.wikipedia.org/wiki/Peter_Brusilovsky) (2007). *The Adaptive Web*. p. 325.\n",
        "5. Robin Burke , [Hybrid Web Recommender Systems](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.435.7538\u0026rep=rep1\u0026type=pdf), pp. 377-408, The Adaptive Web, Peter Brusilovsky, Alfred Kobsa, Wolfgang Nejdl (Ed.), Lecture Notes in Computer Science, Springer-Verlag, Berlin, Germany, Lecture Notes in Computer Science, Vol. 4321, May 2007, 978-3-540-72078-2.\n",
        "6. Yuan, Jianbo, et al. [\"Solving Cold-Start Problem in Large-scale Recommendation Engines: A Deep Learning Approach.\"](https://arxiv.org/pdf/1611.05480v1.pdf) *arXiv preprint arXiv:1611.05480* (2016).\n",
        "7. Covington P, Adams J, Sargin E. [Deep neural networks for youtube recommendations](https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf)[C]//Proceedings of the 10th ACM Conference on Recommender Systems. ACM, 2016: 191-198.\n",
        "\n",
        "\n",
        "\u003cbr/\u003e\n",
        "\u003ca rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"\u003e\u003cimg alt=\"知识共享许可协议\" style=\"border-width:0\" src=\"https://paddlepaddleimage.cdn.bcebos.com/bookimage/camo.png\" /\u003e\u003c/a\u003e\u003cbr /\u003e\u003cspan xmlns:dct=\"http://purl.org/dc/terms/\" href=\"http://purl.org/dc/dcmitype/Text\" property=\"dct:title\" rel=\"dct:type\"\u003e本教程\u003c/span\u003e 由 \u003ca xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://book.paddlepaddle.org\" property=\"cc:attributionName\" rel=\"cc:attributionURL\"\u003ePaddlePaddle\u003c/a\u003e 创作，采用 \u003ca rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"\u003e知识共享 署名-相同方式共享 4.0 国际 许可协议\u003c/a\u003e进行许可。\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
