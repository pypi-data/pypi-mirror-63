{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recommender System\n",
        "\n",
        "The source code of this tutorial is in [book/recommender_system](https://github.com/PaddlePaddle/book/tree/develop/05.recommender_system). For new users, please refer to [Running This Book](https://github.com/PaddlePaddle/book/blob/develop/README.md#running-the-book) .\n",
        "\n",
        "## Background Introduction\n",
        "\n",
        "With the continuous development of network technology and the ever-expanding scale of e-commerce, the number and variety of goods grow rapidly and users need to spend a lot of time to find the goods they want to buy. This is information overload. In order to solve this problem, recommendation system came into being.\n",
        "\n",
        "The recommendation system is a subset of the Information Filtering System, which can be used in a range of areas such as movies, music, e-commerce, and Feed stream recommendations. The recommendation system discovers the user's personalized needs and interests by analyzing and mining user behaviors, and recommends information or products that may be of interest to the user. Unlike search engines, recommendation system do not require users to accurately describe their needs, but model their historical behavior to proactively provide information that meets user interests and needs.\n",
        "\n",
        "The GroupLens system \\[[1](#references)\\] introduced by the University of Minnesota in 1994 is generally considered to be a relatively independent research direction for the recommendation system. The system first proposed the idea of completing recommendation task based on collaborative filtering. After that, the collaborative filtering recommendation based on the model led the development of recommendation system for more than ten years.\n",
        "\n",
        "The traditional personalized recommendation system methods mainly include:\n",
        "\n",
        "- Collaborative Filtering Recommendation: This method is one of the most widely used technologies which requires the collection and analysis of users' historical behaviors, activities and preferences. It can usually be divided into two sub-categories: User-Based Recommendation \\[[1](#references)\\] and Item-Based Recommendation \\[[2](#references)\\]. A key advantage of this method is that it does not rely on the machine to analyze the content characteristics of the item, so it does not need to understand the item itself to accurately recommend complex items such as movies. However, the disadvantage is that there is a cold start problem for new users without any behavior. At the same time, there is also a sparsity problem caused by insufficient interaction data between users and commodities. It is worth mentioning that social network \\[[3](#references)\\] or geographic location and other context information can be integrated into collaborative filtering.\n",
        "- Content-Based Filtering Recommendation \\[[4](#references)\\] : This method uses the content description of the product to abstract meaningful features by calculating the similarity between the user's interest and the product description to make recommendations to users. The advantage is that it is simple and straightforward. It does not need to evaluate products based on the comments of users. Instead, it compares the product similarity by product attributes to recommend similar products to the users of interest. The disadvantage is that there is also a cold start problem for new users without any behavior.\n",
        "- Hybrid Recommendation \\[[5](#references)\\]: Use different inputs and techniques to jointly recommend items to complement each single recommendation technique.\n",
        "\n",
        "In recent years, deep learning has achieved great success in many fields. Both academia and industry are trying to apply deep learning to the field of recommendation systems. Deep learning has excellent ability to automatically extract features, can learn multi-level abstract feature representations, and learn heterogeneous or cross-domain content information, which can deal with the cold start problem \\[[6](#references)\\] of recommendation system to some extent. This tutorial focuses on the deep learning model of recommendation system and how to implement the model with PaddlePaddle.\n",
        "\n",
        "## Result Demo\n",
        "\n",
        "We use a dataset containing user information, movie information, and movie ratings as a recommendation system. When we train the model, we only need to input the corresponding user ID and movie ID, we can get a matching score (range [0, 5], the higher the score is regarded as the greater interest), and then according to the recommendation of all movies sort the scores and recommend them to movies that may be of interest to the user.\n",
        "\n",
        "```\n",
        "Input movie_id: 1962\n",
        "Input user_id: 1\n",
        "Prediction Score is 4.25\n",
        "```\n",
        "\n",
        "## Model Overview\n",
        "\n",
        "In this chapter, we first introduce YouTube's video personalization recommendation system \\[[7](#references)\\], and then introduce the fusion recommendation model we implemented.\n",
        "\n",
        "### YouTube's Deep Neural Network Personalized Recommendation System\n",
        "\n",
        "YouTube is the world's largest video uploading, sharing and discovery site, and the YouTube Personalized Recommendation System recommends personalized content from a growing library to more than 1 billion users. The entire system consists of two neural networks: a candidate generation network and a ranking network. The candidate generation network generates hundreds of candidates from a million-level video library, and the ranking network sorts the candidates and outputs the highest ranked tens of results. The system structure is shown in Figure 1:\n",
        "\n",
        "\u003cp align=\"center\"\u003e\n",
        "\u003cimg src=\"https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/image/YouTube_Overview.png?raw=true\" width=\"70%\" \u003e\u003cbr/\u003e\n",
        "Figure 1. YouTube personalized recommendation system structure\n",
        "\u003c/p\u003e\n",
        "\n",
        "#### Candidate Generation Network\n",
        "\n",
        "The candidate generation network models the recommendation problem as a multi-class classification problem with a large number of categories. For a Youtube user, using its watching history (video ID), search tokens, demographic information (such as geographic location, user login device), binary features (such as gender, whether to log in), and continuous features (such as user age), etc., multi-classify all videos in the video library to obtain the classification result of each category (ie, the recommendation probability of each video), eventually outputting hundreds of videos with high probability.\n",
        "\n",
        "First, the historical information such as watching history and search token records are mapped to vectors and averaged to obtain a fixed length representation. At the same time, demographic characteristics are input to optimize the recommendation effect of new users, and the binary features and continuous features are normalized to the range [0, 1]. Next, put all the feature representations into a vector and input them to the non-linear multilayer perceptron (MLP, see [Identification Figures](https://github.com/PaddlePaddle/book/blob/develop/02.recognize_digits/README.md) tutorial). Finally, during training, the output of the MLP is classified by softmax. When predicting, the similarity of the user's comprehensive features (MLP output) to all videos' features is calculated, and the highest score of $k$ is obtained as the result of the candidate generation network. Figure 2 shows the candidate generation network structure.\n",
        "\n",
        "\u003cp align=\"center\"\u003e\n",
        "\u003cimg src=\"https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/image/Deep_candidate_generation_model_architecture.png?raw=true\" width=\"70%\" \u003e\u003cbr/\u003e\n",
        "Figure 2. Candidate generation network structure\n",
        "\u003c/p\u003e\n",
        "\n",
        "For a user $U$, the formula for predicting whether the video $\\omega$ that the user wants to watch at the moment is video $i$ is:\n",
        "\n",
        "$$P(\\omega=i|u)=\\frac{e^{v_{i}u}}{\\sum_{j \\in V}e^{v_{j}u}}$$\n",
        "\n",
        "Where $u$ is the feature representation of the user $U$, $V$ is the video library collection, and $v_i$ is the feature representation of the $i$ video in the video library. $u$ and $v_i$ are vectors of equal length, and the dot product can be implemented by a fully connected layer.\n",
        "\n",
        "Considering that the number of categories in the softmax classification is very large, in order to ensure a certain computational efficiency: 1) in the training phase, use negative sample category sampling to reduce the number of actually calculated categories to thousands; 2) in the recommendation (prediction) phase, ignore the normalized calculation of softmax (does not affect the result), and simplifies the category scoring problem into the nearest neighbor search problem in the dot product space, then takes the nearest $k$ video of $u$ as a candidate for generation.\n",
        "\n",
        "#### Ranking Network\n",
        "The structure of the ranking network is similar to the candidate generation network, but its goal is to perform finer ranking of the candidates. Similar to the feature extraction method in traditional advertisement ranking, a large number of related features (such as video ID, last watching time, etc.) for video sorting are also constructed here. These features are treated similarly to the candidate generation network, except that at the top of the ranking network is a weighted logistic regression that scores all candidate videos and sorts them from high to low. Then, return to the user.\n",
        "\n",
        "### Fusion recommendation model\n",
        "This section uses Convolutional Neural Networks to learn the representation of movie titles. The convolutional neural network for text and the fusion recommendation model are introduced in turn.\n",
        "\n",
        "#### Convolutional Neural Network (CNN) for text\n",
        "\n",
        "Convolutional neural networks are often used to deal with data of a grid-like topology. For example, an image can be viewed as a pixel of a two-dimensional grid, and a natural language can be viewed as a one-dimensional sequence of words. Convolutional neural networks can extract a variety of local features and combine them to obtain more advanced feature representations. Experiments show that convolutional neural networks can efficiently model image and text problems.\n",
        "\n",
        "The convolutional neural network is mainly composed of convolution and pooling operations, and its application and combination methods are flexible and varied. In this section we will explain the network as shown in Figure 3:\n",
        "\n",
        "\u003cp align=\"center\"\u003e\n",
        "\u003cimg src=\"https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/image/text_cnn.png?raw=true\" width = \"80%\" align=\"center\"/\u003e\u003cbr /\u003e\n",
        "Figure 3. Convolutional neural network text classification model\n",
        "\u003c/p\u003e\n",
        "\n",
        "Suppose the length of the sentence to be processed is $n$, where the word vector of the $i$ word is $x_i\\in\\mathbb{R}^k$, and $k$ is the dimension size.\n",
        "\n",
        "First, splicing the word vector: splicing each $h$ word to form a word window of size $h$, denoted as $x_{i:i+h-1}$, which represents the word sequence splicing of $x_{i}, x_{i+1}, \\ldots, x_{i+h-1}$, where $i$ represents the position of the first word in the word window throughout the sentence, ranging from $1$ to $n-h+1$, $x_{i:i+h-1}\\in\\mathbb{R}^{hk}$.\n",
        "\n",
        "Second, perform a convolution operation: apply the convolution kernel $w\\in\\mathbb{R}^{hk}$ to the window $x_{i:i+h-1}$ containing $h$ words. , get the feature $c_i=f(w\\cdot x_{i:i+h-1}+b)$, where $b\\in\\mathbb{R}$ is the bias and $f$ is the non Linear activation function, such as $sigmoid$. Apply the convolution kernel to all word windows ${x_{1:h}, x_{2:h+1},\\ldots,x_{n-h+1:n}}$ in the sentence, producing a feature map:\n",
        "\n",
        "$$c=[c_1,c_2,\\ldots,c_{n-h+1}], c \\in \\mathbb{R}^{n-h+1}$$\n",
        "\n",
        "Next, using the max pooling over time for feature maps to obtain the feature $\\hat c$, of the whole sentence corresponding to this convolution kernel, which is the maximum value of all elements in the feature map:\n",
        "\n",
        "$$\\hat c=max(c)$$\n",
        "\n",
        "#### Fusion recommendation model overview\n",
        "\n",
        "In the film personalized recommendation system that incorporates the recommendation model:\n",
        "\n",
        "1. First, take user features and movie features as input to the neural network, where:\n",
        "\n",
        "   - The user features incorporate four attribute information: user ID, gender, occupation, and age.\n",
        "\n",
        "   - The movie feature incorporate three attribute information: movie ID, movie type ID, and movie name.\n",
        "\n",
        "2. For the user feature, map the user ID to a vector representation with a dimension size of 256, enter the fully connected layer, and do similar processing for the other three attributes. Then the feature representations of the four attributes are fully connected and added separately.\n",
        "\n",
        "3. For movie features, the movie ID is processed in a manner similar to the user ID. The movie type ID is directly input into the fully connected layer in the form of a vector, and the movie name is represented by a fixed-length vector using a text convolutional neural network. The feature representations of the three attributes are then fully connected and added separately.\n",
        "\n",
        "4. After obtaining the vector representation of the user and the movie, calculate the cosine similarity of them as the score of the personalized recommendation system. Finally, the square of the difference between the similarity score and the user's true score is used as the loss function of the regression model.\n",
        "\n",
        "\u003cp align=\"center\"\u003e\n",
        "\u003cimg src=\"https://github.com/PaddlePaddle/book/blob/develop/05.recommender_system/image/rec_regression_network.png?raw=true\" width=\"90%\" \u003e\u003cbr/\u003e\n",
        "Figure 4. Fusion recommendation model\n",
        "\u003c/p\u003e\n",
        "\n",
        "## Data Preparation\n",
        "\n",
        "### Data Introduction and Download\n",
        "\n",
        "We take [MovieLens Million Dataset (ml-1m)](http://files.grouplens.org/datasets/movielens/ml-1m.zip) as an example. The ml-1m dataset contains 1,000,000 reviews of 4,000 movies by 6,000 users (scores ranging from 1 to 5, all integer), collected by the GroupLens Research lab.\n",
        "\n",
        "Paddle provides modules for automatically loading data in the API. The data module is `paddle.dataset.movielens`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "from __future__ import print_function\n",
        "import paddle\n",
        "movie_info = paddle.dataset.movielens.movie_info()\n",
        "print(list(movie_info.values())[0])\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "# Run this block to show dataset's documentation\n",
        "# help(paddle.dataset.movielens)\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The original data includes feature data of the movie, user's feature data, and the user's rating of the movie.\n",
        "\n",
        "For example, one of the movie features is:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "movie_info = paddle.dataset.movielens.movie_info()\n",
        "print(list(movie_info.values())[0])\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    \u003cMovieInfo id(1), title(Toy Story ), categories(['Animation', \"Children's\", 'Comedy'])\u003e\n",
        "\n",
        "\n",
        "This means that the movie id is 1, and the title is 《Toy Story》, which is divided into three categories. These three categories are animation, children, and comedy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "user_info = paddle.dataset.movielens.user_info()\n",
        "print(list(user_info.values())[0])\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    \u003cUserInfo id(1), gender(F), age(1), job(10)\u003e\n",
        "\n",
        "\n",
        "This means that the user ID is 1, female, and younger than 18 years old. The occupation ID is 10.\n",
        "\n",
        "\n",
        "Among them, the age uses the following distribution\n",
        "\n",
        "*  1:  \"Under 18\"\n",
        "* 18:  \"18-24\"\n",
        "* 25:  \"25-34\"\n",
        "* 35:  \"35-44\"\n",
        "* 45:  \"45-49\"\n",
        "* 50:  \"50-55\"\n",
        "* 56:  \"56+\"\n",
        "\n",
        "The occupation is selected from the following options:\n",
        "\n",
        "*  0:  \"other\" or not specified\n",
        "*  1:  \"academic/educator\"\n",
        "*  2:  \"artist\"\n",
        "*  3:  \"clerical/admin\"\n",
        "*  4:  \"college/grad student\"\n",
        "*  5:  \"customer service\"\n",
        "*  6:  \"doctor/health care\"\n",
        "*  7:  \"executive/managerial\"\n",
        "*  8:  \"farmer\"\n",
        "*  9:  \"homemaker\"\n",
        "* 10:  \"K-12 student\"\n",
        "* 11:  \"lawyer\"\n",
        "* 12:  \"programmer\"\n",
        "* 13:  \"retired\"\n",
        "* 14:  \"sales/marketing\"\n",
        "* 15:  \"scientist\"\n",
        "* 16:  \"self-employed\"\n",
        "* 17:  \"technician/engineer\"\n",
        "* 18:  \"tradesman/craftsman\"\n",
        "* 19:  \"unemployed\"\n",
        "* 20:  \"writer\"\n",
        "\n",
        "For each training or test data, it is \u003cuser features\u003e + \u003cmovie feature\u003e + rating.\n",
        "\n",
        "For example, we get the first training data:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "train_set_creator = paddle.dataset.movielens.train()\n",
        "train_sample = next(train_set_creator())\n",
        "uid = train_sample[0]\n",
        "mov_id = train_sample[len(user_info[uid].value())]\n",
        "print(\"User %s rates Movie %s with Score %s\"%(user_info[uid], movie_info[mov_id], train_sample[-1]))\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "    User \u003cUserInfo id(1), gender(F), age(1), job(10)\u003e rates Movie \u003cMovieInfo id(1193), title(One Flew Over the Cuckoo's Nest ), categories(['Drama'])\u003e with Score [5.0]\n",
        "\n",
        "\n",
        "That is, the user 1 evaluates the movie 1193 as 5 points.\n",
        "\n",
        "## Configuration Instruction\n",
        "\n",
        "Below we begin to configure the model based on the form of the input data. First import the required library functions and define global variables.\n",
        "\n",
        "- IS_SPARSE: whether to use sparse update in embedding\n",
        "- PASS_NUM: number of epoch\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "import math\n",
        "import sys\n",
        "import numpy as np\n",
        "import paddle\n",
        "import paddle.fluid as fluid\n",
        "import paddle.fluid.layers as layers\n",
        "import paddle.fluid.nets as nets\n",
        "\n",
        "IS_SPARSE = True\n",
        "BATCH_SIZE = 256\n",
        "PASS_NUM = 20\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Then define the model configuration for our user feature synthesis model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "def get_usr_combined_features():\n",
        "    \"\"\"network definition for user part\"\"\"\n",
        "\n",
        "    USR_DICT_SIZE = paddle.dataset.movielens.max_user_id() + 1\n",
        "\n",
        "    uid = layers.data(name='user_id', shape=[1], dtype='int64')\n",
        "\n",
        "    usr_emb = layers.embedding(\n",
        "        input=uid,\n",
        "        dtype='float32',\n",
        "        size=[USR_DICT_SIZE, 32],\n",
        "        param_attr='user_table',\n",
        "        is_sparse=IS_SPARSE)\n",
        "\n",
        "    usr_fc = layers.fc(input=usr_emb, size=32)\n",
        "\n",
        "    USR_GENDER_DICT_SIZE = 2\n",
        "\n",
        "    usr_gender_id = layers.data(name='gender_id', shape=[1], dtype='int64')\n",
        "\n",
        "    usr_gender_emb = layers.embedding(\n",
        "        input=usr_gender_id,\n",
        "        size=[USR_GENDER_DICT_SIZE, 16],\n",
        "        param_attr='gender_table',\n",
        "        is_sparse=IS_SPARSE)\n",
        "\n",
        "    usr_gender_fc = layers.fc(input=usr_gender_emb, size=16)\n",
        "\n",
        "    USR_AGE_DICT_SIZE = len(paddle.dataset.movielens.age_table)\n",
        "    usr_age_id = layers.data(name='age_id', shape=[1], dtype=\"int64\")\n",
        "\n",
        "    usr_age_emb = layers.embedding(\n",
        "        input=usr_age_id,\n",
        "        size=[USR_AGE_DICT_SIZE, 16],\n",
        "        is_sparse=IS_SPARSE,\n",
        "        param_attr='age_table')\n",
        "\n",
        "    usr_age_fc = layers.fc(input=usr_age_emb, size=16)\n",
        "\n",
        "    USR_JOB_DICT_SIZE = paddle.dataset.movielens.max_job_id() + 1\n",
        "    usr_job_id = layers.data(name='job_id', shape=[1], dtype=\"int64\")\n",
        "\n",
        "    usr_job_emb = layers.embedding(\n",
        "        input=usr_job_id,\n",
        "        size=[USR_JOB_DICT_SIZE, 16],\n",
        "        param_attr='job_table',\n",
        "        is_sparse=IS_SPARSE)\n",
        "\n",
        "    usr_job_fc = layers.fc(input=usr_job_emb, size=16)\n",
        "\n",
        "    concat_embed = layers.concat(\n",
        "        input=[usr_fc, usr_gender_fc, usr_age_fc, usr_job_fc], axis=1)\n",
        "\n",
        "    usr_combined_features = layers.fc(input=concat_embed, size=200, act=\"tanh\")\n",
        "\n",
        "    return usr_combined_features\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "As shown in the code above, for each user, we enter a 4-dimensional feature. This includes user_id, gender_id, age_id, job_id. These dimensional features are simple integer values. In order to facilitate the subsequent neural network processing of these features, we use the language model in NLP to transform these discrete integer values ​​into embedding. And form them into usr_emb, usr_gender_emb, usr_age_emb, usr_job_emb, respectively.\n",
        "\n",
        "Then, we enter all the user features into a fully connected layer(fc). Combine all features into one 200-dimension feature.\n",
        "\n",
        "Furthermore, we make a similar transformation for each movie feature, the network configuration is:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "def get_mov_combined_features():\n",
        "    \"\"\"network definition for item(movie) part\"\"\"\n",
        "\n",
        "    MOV_DICT_SIZE = paddle.dataset.movielens.max_movie_id() + 1\n",
        "\n",
        "    mov_id = layers.data(name='movie_id', shape=[1], dtype='int64')\n",
        "\n",
        "    mov_emb = layers.embedding(\n",
        "        input=mov_id,\n",
        "        dtype='float32',\n",
        "        size=[MOV_DICT_SIZE, 32],\n",
        "        param_attr='movie_table',\n",
        "        is_sparse=IS_SPARSE)\n",
        "\n",
        "    mov_fc = layers.fc(input=mov_emb, size=32)\n",
        "\n",
        "    CATEGORY_DICT_SIZE = len(paddle.dataset.movielens.movie_categories())\n",
        "\n",
        "    category_id = layers.data(\n",
        "        name='category_id', shape=[1], dtype='int64', lod_level=1)\n",
        "\n",
        "    mov_categories_emb = layers.embedding(\n",
        "        input=category_id, size=[CATEGORY_DICT_SIZE, 32], is_sparse=IS_SPARSE)\n",
        "\n",
        "    mov_categories_hidden = layers.sequence_pool(\n",
        "        input=mov_categories_emb, pool_type=\"sum\")\n",
        "\n",
        "    MOV_TITLE_DICT_SIZE = len(paddle.dataset.movielens.get_movie_title_dict())\n",
        "\n",
        "    mov_title_id = layers.data(\n",
        "        name='movie_title', shape=[1], dtype='int64', lod_level=1)\n",
        "\n",
        "    mov_title_emb = layers.embedding(\n",
        "        input=mov_title_id, size=[MOV_TITLE_DICT_SIZE, 32], is_sparse=IS_SPARSE)\n",
        "\n",
        "    mov_title_conv = nets.sequence_conv_pool(\n",
        "        input=mov_title_emb,\n",
        "        num_filters=32,\n",
        "        filter_size=3,\n",
        "        act=\"tanh\",\n",
        "        pool_type=\"sum\")\n",
        "\n",
        "    concat_embed = layers.concat(\n",
        "        input=[mov_fc, mov_categories_hidden, mov_title_conv], axis=1)\n",
        "\n",
        "    mov_combined_features = layers.fc(input=concat_embed, size=200, act=\"tanh\")\n",
        "\n",
        "    return mov_combined_features\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "The title of a movie is a sequence of integers, and the integer represents the subscript of the word in the index sequence. This sequence is sent to the `sequence_conv_pool` layer, which uses convolution and pooling on the time dimension. Because of this, the output will be fixed length, although the length of the input sequence will vary.\n",
        "\n",
        "Finally, we define an `inference_program` to calculate the similarity between user features and movie features using cosine similarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "def inference_program():\n",
        "    \"\"\"the combined network\"\"\"\n",
        "\n",
        "    usr_combined_features = get_usr_combined_features()\n",
        "    mov_combined_features = get_mov_combined_features()\n",
        "\n",
        "    inference = layers.cos_sim(X=usr_combined_features, Y=mov_combined_features)\n",
        "    scale_infer = layers.scale(x=inference, scale=5.0)\n",
        "\n",
        "    return scale_infer\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Furthermore, we define a `train_program` to use the result computed by `inference_program`, and calculate the error with the help of the tag data. We also define an `optimizer_func` to define the optimizer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "def train_program():\n",
        "    \"\"\"define the cost function\"\"\"\n",
        "\n",
        "    scale_infer = inference_program()\n",
        "\n",
        "    label = layers.data(name='score', shape=[1], dtype='float32')\n",
        "    square_cost = layers.square_error_cost(input=scale_infer, label=label)\n",
        "    avg_cost = layers.mean(square_cost)\n",
        "\n",
        "    return [avg_cost, scale_infer]\n",
        "\n",
        "\n",
        "def optimizer_func():\n",
        "    return fluid.optimizer.SGD(learning_rate=0.2)\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "## Training Model\n",
        "\n",
        "### Defining the training environment\n",
        "Define your training environment and specify whether the training takes place on CPU or GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "use_cuda = False\n",
        "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Defining the data provider\n",
        "The next step is to define a data provider for training and testing. The provider reads in a data of size `BATCH_SIZE`. `paddle.dataset.movielens.train` will provide a data of size `BATCH_SIZE` after each scribbling, and the size of the out-of-order is the cache size `buf_size`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "train_reader = paddle.batch(\n",
        "    paddle.reader.shuffle(\n",
        "        paddle.dataset.movielens.train(), buf_size=8192),\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "test_reader = paddle.batch(\n",
        "    paddle.dataset.movielens.test(), batch_size=BATCH_SIZE)\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Constructing a training process (trainer)\n",
        "We have constructed a training process here, including training optimization functions.\n",
        "\n",
        "### Provide data\n",
        "\n",
        "`feed_order` is used to define the mapping between each generated data and `paddle.layer.data`. For example, the data in the first column generated by `movielens.train` corresponds to the feature `user_id`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "feed_order = [\n",
        "    'user_id', 'gender_id', 'age_id', 'job_id', 'movie_id', 'category_id',\n",
        "    'movie_title', 'score'\n",
        "]\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Building training programs and testing programs\n",
        "The training program and the test program are separately constructed, and the training optimizer is imported.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "main_program = fluid.default_main_program()\n",
        "star_program = fluid.default_startup_program()\n",
        "[avg_cost, scale_infer] = train_program()\n",
        "\n",
        "test_program = main_program.clone(for_test=True)\n",
        "sgd_optimizer = optimizer_func()\n",
        "sgd_optimizer.minimize(avg_cost)\n",
        "exe = fluid.Executor(place)\n",
        "\n",
        "def train_test(program, reader):\n",
        "    count = 0\n",
        "    feed_var_list = [\n",
        "        program.global_block().var(var_name) for var_name in feed_order\n",
        "    ]\n",
        "    feeder_test = fluid.DataFeeder(\n",
        "    feed_list=feed_var_list, place=place)\n",
        "    test_exe = fluid.Executor(place)\n",
        "    accumulated = 0\n",
        "    for test_data in reader():\n",
        "        avg_cost_np = test_exe.run(program=program,\n",
        "                                               feed=feeder_test.feed(test_data),\n",
        "                                               fetch_list=[avg_cost])\n",
        "        accumulated += avg_cost_np[0]\n",
        "        count += 1\n",
        "    return accumulated / count\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Build a training main loop and start training\n",
        "We perform the training cycle according to the training cycle number (`PASS_NUM`) defined above and some other parameters, and perform a test every time. When the test result is good enough, we exit the training and save the trained parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "# Specify the directory path to save the parameters\n",
        "params_dirname = \"recommender_system.inference.model\"\n",
        "\n",
        "from paddle.utils.plot import Ploter\n",
        "train_prompt = \"Train cost\"\n",
        "test_prompt = \"Test cost\"\n",
        "\n",
        "plot_cost = Ploter(train_prompt, test_prompt)\n",
        "\n",
        "def train_loop():\n",
        "    feed_list = [\n",
        "        main_program.global_block().var(var_name) for var_name in feed_order\n",
        "    ]\n",
        "    feeder = fluid.DataFeeder(feed_list, place)\n",
        "    exe.run(star_program)\n",
        "\n",
        "    for pass_id in range(PASS_NUM):\n",
        "        for batch_id, data in enumerate(train_reader()):\n",
        "            # train a mini-batch\n",
        "            outs = exe.run(program=main_program,\n",
        "                               feed=feeder.feed(data),\n",
        "                               fetch_list=[avg_cost])\n",
        "            out = np.array(outs[0])\n",
        "\n",
        "            # get test avg_cost\n",
        "            test_avg_cost = train_test(test_program, test_reader)\n",
        "\n",
        "            plot_cost.append(train_prompt, batch_id, outs[0])\n",
        "            plot_cost.append(test_prompt, batch_id, test_avg_cost)\n",
        "            plot_cost.plot()\n",
        "\n",
        "            if batch_id == 20:\n",
        "                if params_dirname is not None:\n",
        "                    fluid.io.save_inference_model(params_dirname, [\n",
        "                                \"user_id\", \"gender_id\", \"age_id\", \"job_id\",\n",
        "                                \"movie_id\", \"category_id\", \"movie_title\"\n",
        "                        ], [scale_infer], exe)\n",
        "                return\n",
        "            print('EpochID {0}, BatchID {1}, Test Loss {2:0.2}'.format(\n",
        "                            pass_id + 1, batch_id + 1, float(test_avg_cost)))\n",
        "\n",
        "            if math.isnan(float(out[0])):\n",
        "                sys.exit(\"got NaN loss, training failed.\")\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "train_loop()\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Model Application\n",
        "\n",
        "### Generate test data\n",
        "Use the API of create_lod_tensor(data, lod, place) to generate the tensor of the detail level. `data` is a sequence, and each element is a sequence of index numbers. `lod` is the detail level's information, corresponding to `data`. For example, data = [[10, 2, 3], [2, 3]] means that it contains two sequences of lengths 3 and 2. Correspondingly lod = [[3, 2]], which indicates that it contains a layer of detail information, meaning that `data` has two sequences, lengths of 3 and 2.\n",
        "\n",
        "In this prediction example, we try to predict the score given by user with ID1 for the movie 'Hunchback of Notre Dame'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "infer_movie_id = 783\n",
        "infer_movie_name = paddle.dataset.movielens.movie_info()[infer_movie_id].title\n",
        "user_id = fluid.create_lod_tensor([[1]], [[1]], place)\n",
        "gender_id = fluid.create_lod_tensor([[1]], [[1]], place)\n",
        "age_id = fluid.create_lod_tensor([[0]], [[1]], place)\n",
        "job_id = fluid.create_lod_tensor([[10]], [[1]], place)\n",
        "movie_id = fluid.create_lod_tensor([[783]], [[1]], place) # Hunchback of Notre Dame\n",
        "category_id = fluid.create_lod_tensor([[10, 8, 9]], [[3]], place) # Animation, Children's, Musical\n",
        "movie_title = fluid.create_lod_tensor([[1069, 4140, 2923, 710, 988]], [[5]],\n",
        "                                      place) # 'hunchback','of','notre','dame','the'\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Building the prediction process and testing\n",
        "Similar to the training process, we need to build a prediction process, where `params_dirname` is the address used to store the various parameters in the training process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\n",
        "exe = fluid.Executor(place)\n",
        "\n",
        "inference_scope = fluid.core.Scope()\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Testing\n",
        "Now we can make predictions. The `feed_order` we provide should be consistent with the training process.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "editable": true
      },
      "source": [
        "with fluid.scope_guard(inference_scope):\n",
        "    [inferencer, feed_target_names,\n",
        "    fetch_targets] = fluid.io.load_inference_model(params_dirname, exe)\n",
        "\n",
        "    results = exe.run(inferencer,\n",
        "                          feed={\n",
        "                               'user_id': user_id,\n",
        "                              'gender_id': gender_id,\n",
        "                              'age_id': age_id,\n",
        "                              'job_id': job_id,\n",
        "                              'movie_id': movie_id,\n",
        "                              'category_id': category_id,\n",
        "                              'movie_title': movie_title\n",
        "                          },\n",
        "                          fetch_list=fetch_targets,\n",
        "                          return_numpy=False)\n",
        "    predict_rating = np.array(results[0])\n",
        "    print(\"Predict Rating of user id 1 on movie \\\"\" + infer_movie_name +\n",
        "              \"\\\" is \" + str(predict_rating[0][0]))\n",
        "    print(\"Actual Rating of user id 1 on movie \\\"\" + infer_movie_name +\n",
        "              \"\\\" is 4.\")\n"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Summary\n",
        "\n",
        "This chapter introduced the traditional personalized recommendation system method and YouTube's deep neural network personalized recommendation system. It further took movie recommendation as an example, and used PaddlePaddle to train a personalized recommendation neural network model. The personalized recommendation system covers almost all aspects of e-commerce systems, social networks, advertising recommendations, search engines, etc. Deep learning technologies have played an important role in image processing, natural language processing, etc., and will also prevail in personalized recommendation systems.\n",
        "\n",
        "\u003ca name=\"references\"\u003e\u003c/a\u003e\n",
        "## References\n",
        "\n",
        "1. P. Resnick, N. Iacovou, etc. “[GroupLens: An Open Architecture for Collaborative Filtering of Netnews](http://ccs.mit.edu/papers/CCSWP165.html)”, Proceedings of ACM Conference on Computer Supported Cooperative Work, CSCW 1994. pp.175-186.\n",
        "2. Sarwar, Badrul, et al. \"[Item-based collaborative filtering recommendation algorithms.](http://files.grouplens.org/papers/www10_sarwar.pdf)\" *Proceedings of the 10th international conference on World Wide Web*. ACM, 2001.\n",
        "3. Kautz, Henry, Bart Selman, and Mehul Shah. \"[Referral Web: combining social networks and collaborative filtering.](http://www.cs.cornell.edu/selman/papers/pdf/97.cacm.refweb.pdf)\" Communications of the ACM 40.3 (1997): 63-65. APA\n",
        "4. [Peter Brusilovsky](https://en.wikipedia.org/wiki/Peter_Brusilovsky) (2007). *The Adaptive Web*. p. 325.\n",
        "5. Robin Burke , [Hybrid Web recommendation systems](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.435.7538\u0026rep=rep1\u0026type=pdf), pp. 377-408, The Adaptive Web, Peter Brusilovsky, Alfred Kobsa, Wolfgang Nejdl (Ed.), Lecture Notes in Computer Science, Springer-Verlag, Berlin, Germany, Lecture Notes in Computer Science, Vol. 4321, May 2007, 978-3-540-72078-2.\n",
        "6. Yuan, Jianbo, et al. [\"Solving Cold-Start Problem in Large-scale Recommendation Engines: A Deep Learning Approach.\"](https://arxiv.org/pdf/1611.05480v1.pdf) *arXiv preprint arXiv:1611.05480* (2016).\n",
        "7. Covington P, Adams J, Sargin E. [Deep neural networks for youtube recommendations](https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/45530.pdf)[C]//Proceedings of the 10th ACM Conference on recommendation systems. ACM, 2016: 191-198.\n",
        "\n",
        "\n",
        "\u003cbr/\u003e\n",
        "\u003ca rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"\u003e\u003cimg alt=\"知识共享许可协议\" style=\"border-width:0\" src=\"https://paddlepaddleimage.cdn.bcebos.com/bookimage/camo.png\" /\u003e\u003c/a\u003e\u003cbr /\u003e\u003cspan xmlns:dct=\"http://purl.org/dc/terms/\" href=\"http://purl.org/dc/dcmitype/Text\" property=\"dct:title\" rel=\"dct:type\"\u003eThis tutorial\u003c/span\u003e is contributed by \u003ca xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://book.paddlepaddle.org\" property=\"cc:attributionName\" rel=\"cc:attributionURL\"\u003ePaddlePaddle\u003c/a\u003e, and licensed under a \u003ca rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"\u003eCreative Commons Attribution-ShareAlike 4.0 International License\u003c/a\u003e.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
