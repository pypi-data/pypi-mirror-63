AudioFileInfo:

    format_description
    path
    length
    num_channels
    sample_rate
    sample_size
    
    
AudioFileReader(AudioFileInfo):

    static methods
    --------------
    is_recognized_file(path)
    create_reader(path)
    
    instance methods
    ----------------
    read(length=None, start_index=None, out=None)
    close()


2019-11-12 Comments:

* I think it might be best to rename `Signal` to `Channel` and
`MultichannelSignal` to `Signal`, so that a signal always has one
or more channels. This is inconsistent with how the term "signal" is
usually used in the field of signal processing (what is usually
called a "signal" there I propose calling a "channel", while
what I propose calling a "signal" is usually called a "signal array"
or something like that), but I believe it better represents the
reality of actual computational signal processing, which frequently
involves signals with multiple channels, e.g. stereo audio signals.

* I think it would be best to prefer the term "sample" to "sample value"
or "value". So, for example, we should prefer to talk about the
"sample range" of a signal rather than its "value range". I think I
would like to retain the term "amplitude axis", however, rather than
using "sample axis", since it is primarily for what is better called
"amplitude calibrarion" than "sample calibration".

* I think it would be best not to use the terms "array signal" and
"array channel", since "array" in those terms would refer to something
different (a NumPy array containing all of the samples of a signal)
than "array" in terms like "sample array" and "array axis" (an array
of samples at a particular time). Maybe "RAM signal" and
"RAM channel" instead?

* A signal has an optional sample range (minSample, maxSample) that
indicates the range in which its samples may be expected to fall.
The range may not be tight, and in some cases samples may even lie
outside of it: the range provides a guide to, but not necessarily a
guarantee of, the range of samples of the signal.

* The sample range for an audio file signal is determined by the
file's sample type. For example, the sample range for an audio file
with 16-bit, two's complement samples is (-32768, 32767).

* A signal with a sample range can be wrapped using the `ScaledSignal`
class to create a scaled version of that signal. The scaled signal has
all of the same properties as the wrapped signal except for its sample
range and perhaps dtype. The `ScaledSignal` scales samples on the fly
as they are read. For example, in:

    signal = AudioFileSignal('test.wav')
    scaled_signal = SignalScaler(
        signal, sample_range=(-1, 1), dtype='float32'))
        
`signal` has a sample range determined by the format of the audio file
*test.wav*, while `scaled_signal` is a scaled version of `signal` with
a sample range of [-1, 1] and a float32 dtype.

* Since it will be very common to want to normalize the samples of
audio file signals, it might be a good idea to build sample scaling
into `AudioFileSignal` and `AudioFileWriter`. For example, instead
of the above we might write just:

    scaled_signal = AudioFileSignal(
        'test.wav', sample_range=(-1, 1), dtype='float32')
        
Scaling might happen by default when writing a signal to an audio file
(or an audio file sequence), according to the sample ranges of the signal
and the audio file format. If so it should also be possible to disable
the scaling, say via a `sample_scaling_enabled` keyword argument that is
`True` by default.

Something similar would presumably also be desirable for real-time
audio I/O.

* Signal sample types we will support and the corresponding sample ranges
are:
    8-bit unsigned integer: (0, 255)
    8-bit integer: (-128, 127)
    16-bit integer: (-32768, 32767)
    24-bit integer: (-(2**23), 2**23 - 1)
    32-bit float: (-1, 1) when read from an audio file with normalization
    64-bit float: (-1, 1) when read from an audio file with normalization
    
General points about signals:

* One important design goal is for `Signal` and `Channel` instances to
behave as much as possible like NumPy arrays. This will allow users
already familiar with NumPy arrays to use `Signal` and `Channel` more
easily. So, for example, `Signal` and `Channel` instances will have
shapes and lengths just like NumPy arrays, and indexing them will
behave just like indexing a NumPy array of the same shape.

* With the preceding point in mind, `Signal` and `Channel` instances
will support negative array indices, with such an index indexing an
instance relative to its end. We will *not* allow the use of negative
indices to index a `Signal` or `Channel` left of the origin. Such
indexing is common in the field of signal processing, but Vesper
signal index ranges will all start at zero.

* I'm a little uncomfortable with the idea that the length of a
signal is the number of its channels, while the length of a channel
is the number of its sample arrays. I think of signals both as
sequences of sample frames and as sets of channels. But the proposed
length semantics *are* consistent with the idea of making signals and
channels behave as much like NumPy arrays as possible. Perhaps `Signal`
and `Channel` should both have `num_frames` properties, and `Signal`
should have a `num_channels` property, and their use should be
encouraged for clarity.

* How might we support multichannel signals where the channels are
recorded by different instruments, perhaps with different start times
and sample rates?

* Can we support signals whose sample rates differ a little from their
nominal sample rates, and whose sample rates vary a little, for example
with temperature?


Signal

* Sequence of `Channel` objects.
* All channels have the same shape.
* Sequence of sample arrays at a given signal index is a *sample frame*.
* Indexing yields NumPy array of samples.
* First index is channel number.
* Second index is for time axis.
* Other indices are for sample array axes.
* Each channel has its own amplitude axis.

s.name

s.channels                 # `NamedSequence` of `Channel` objects

s.time_axis                # `TimeAxis`
s.array_axes               # `NamedSequence` of `ArrayAxis` objects
s.sample_axis              # `SampleAxis`
s.axes                     # mapping from axis name to axis object

s.dtype                    # NumPy sample `dtype`

s.shape                    # tuple of number of channels and axis lengths
len(s)                     # number of channels

s[:]                       # all samples of all channels
s[0]                       # all samples of channel 0
s[0, 10]                   # sample array 10 of channel 0
s[0, 10:20]                # sample arrays 10 through 19 of channel 0
s[:, 10]                   # sample frame 10
s[:, 10:20]                # sample frames 10 through 19


Channel

* Sequence of n-dimensional sample arrays.
* All sample arrays of a channel have the same dimensions.
* Indexing yields NumPy array of samples.
* First index is for time axis.
* Other indices are for sample array axes.
* Time axis has a nonnegative start index and a nonnegative length.
* Reading outside of extent raises an exception (might optionally zero fill)
* Implement only immutable channels initially, then perhaps extendible
  and editable signals. Those will probably require some sort of thread
  synchronization.

s.name                     # `str` or `None`

s.signal                   # `Signal` or `None`

s.time_axis                # `TimeAxis`
s.array_axes               # `NamedSequence` of `ArrayAxis` objects
s.sample_axis              # `SampleAxis`
s.axes                     # mapping from axis name to axis object

s.dtype                    # NumPy sample `dtype`

s.shape                    # signal shape, an integer tuple
len(s)                     # time axis length

s[:]                       # all signal samples
s[0]                       # sample array 0
s[1]                       # sample array 1
s[-1]                      # final sample array
s[0:10]                    # sample arrays 0 through 9
s[0, 10:20]                # part of sample array 0
s[0, 10:-20]               # part of sample array 0


Axis

a.name                     # e.g. 'Time', 'Frequency'
a.units                    # `Bunch` with `plural`, `singular`, and
                           # `abbreviation` attributes


IndexedAxis(Axis)

The range of valid indices for an `IndexedAxis` is [0, length - 1].

a.length                   # axis length in indices


TimeAxis(IndexedAxis)

Axis values have units of seconds. A `TimeAxis` may be *date/time calibrated*,
in which case the date and time of each sample is known. Note that we must
be careful when computing spans that we do not assume that the index to
seconds mapping is linear!

a.sample_rate              # hertz
a.sample_period            # seconds

a.index_to_seconds_mapping
a.index_to_seconds(i)      # `i` in [0, length], scalar or array, int or float
a.seconds_to_index(t)      # `t` can be scalar or array. Result is float
                           # Maybe offer rounded int result as an option?
a.get_span(i, j)           # `index_to_seconds[j] - index_to_seconds[i]`
a.span                     # `get_span(0, length - 1)`, or zero if length zero
a.duration                 # `get_span(0, length)`

a.index_to_datetime_mapping
a.index_to_datetime(i)     # `i` can be scalar or array, int or float.
a.datetime_to_index(dt)    # `dt` can be scalar or array. Result is float.

a.start_datetime           # `datetime` at start index, `None` if unknown
a.end_datetime             # `datetime` at end index, `None` if unknown


ArrayAxis(IndexedAxis)

a.index_to_value_mapping
a.index_to_value(i)        # `i` can be scalar or array, int or float
a.value_to_index(v)        # `v` can b scalar or array. Result is float.

a.start_value              # value at index zero
a.end_value                # value at index length - 1, `None` if length zero
a.span                     # end value less start value, `None` if length zero


AmplitudeAxis(Axis)

For now, `AmplitudeAxis` is just a subclass of `Axis` with a specialized
initializer and no other methods. It will (probably) eventually provide
amplitude calibration functionality. Note that we may want to allow
different sample axes for different signal channels, since different
channels may require different amplitude calibrations.


* How do we support mutable signals? The two types of mutable signals
  I can think of are *extensible* signals and *editable* signals. The
  available extent of an extensible signal can change, but the sample
  values (i.e. the values of the samples of any particular sample array)
  of the signal never change. Both the available extent and the sample
  values of an editable signal can change via cut and paste operations.
  [Why have two classes of mutable signals? Why not have just editable
  signals (though we might just call them mutable), which subsume
  extendible signals?]
  
  Mutability complicates signal processing. I have in mind implementing
  signal processing lazily inside various `Signal` subclasses. For
  example, I would like to implement a `Spectrogram` subclass, an
  instance of which computes a spectrogram of a wrapped waveform.
  To support mutability, I have in mind making `Signal` instances
  observable. Then a `Signal` that wraps another signal can observe
  that signal, so that whenever the latter changes the former can
  notify its observers of how it, in turn, has changed. The
  notifications would include an indication of where along the time
  axis the changes occurred.
  
  [Some signal processors might two or more output signals. For
  example, a spectrograph might offer complex, magnitude, and
  phase output signals. In this case the spectrograph would not
  itself be a `Signal` or a `MultichannelSignal`, but would be
  some other type of object (a `SignalProcessor`, perhaps) that
  would offer several output signals, and that might tailor its
  computation to which of those outputs are being observed. If
  only the magnitude output of a spectrograph is being observed,
  for example, it might use the SciPy `spectrogram` function
  differently (in particular, to compute only the spectrogram
  magnitude) than it would if its complex output was being
  observed.
  
  We will also have to concern ourselves with thread synchronization
  for mutable signals. We might just use locks for this, perhaps in
  conjunction with Python's `with` statement.
  
  It seems to me that it might be good for the signal classes to
  explicitly acknowledge the difference between real-time signals,
  for which change is steady and predictable and places certain
  constraints on processing, and editable signals, for which change
  is less predictable but doesn't constrain processing as heavily.
  The two cases are really quite different.

  
Audio File Utils
  
u.get_audio_file_type(file_path)
u.create_audio_file_ram_signal(file_)
u.create_audio_file_signal(file_)
  