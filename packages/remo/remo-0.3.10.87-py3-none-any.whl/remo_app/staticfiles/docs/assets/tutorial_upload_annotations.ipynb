{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we explore some of different options available to upload annotations in Remo. We will:\n",
    "- introduce the concept of Annotation set\n",
    "- add annotations using a file format supported by Remo\n",
    "- add annotations directly from code\n",
    "- add annotations using custom files formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by creating a dataset and populating it with some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Remo server ...\n",
      "Wait a bit...  5\n",
      "\n",
      "    (\\(\\ \n",
      "    (>':') Remo server is running: {'app': 'remo', 'version': '0.3.10-53-g3012aa79'}\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import remo\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "urls = ['https://remo-scripts.s3-eu-west-1.amazonaws.com/open_images_sample_dataset.zip']\n",
    "my_dataset = remo.create_dataset(name = 'D1', urls = urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation sets represent a collection of annotations for all the images within a Dataset.\n",
    "An annotation set is characterized by a task (such as 'Object Detection') and a list of classes.\n",
    "\n",
    "The advantage of grouping annotations in an Annotation Set is that it allows for high-level group operations on all the annotations, such:\n",
    "- grouping classes together\n",
    "- deleting objects of specific classes\n",
    "- comparing of different annotations (such as ground truth vs prediction, or annotations coming from different annotators)\n",
    "\n",
    "\n",
    "**Let's first create an empty annotation set with a predetermined list of classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes = ['Airplane', 'Clothing', 'Dog', 'Fashion accessory', 'Food', 'Footwear', 'Fruit', 'Human arm', \n",
    "         'Human body', 'Human hand', 'Human leg', 'Mammal', 'Man', 'Person', 'Salad', 'Sports equipment', 'Trousers', 'Woman']\n",
    "\n",
    "annotation_set = my_dataset.create_annotation_set(annotation_task = 'Object detection',\n",
    "                                          name = 'Objects',\n",
    "                                          classes = my_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily retrieve different annotation sets of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Annotation set 17 - 'Objects', task: Object detection, #classes: 18]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.annotation_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations from supported CSV file format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's add some annotations from a CSV file**\n",
    "\n",
    "In this example, annotations are stored in a CSV file in a format already supported by Remo. Class labels were encoded using [GoogleKnowledgeGraph](https://developers.google.com/knowledge-graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ImageID', 'Source', 'LabelName', 'Confidence', 'XMin', 'XMax', 'YMin',\n",
       "       'YMax', 'IsOccluded', 'IsTruncated', 'IsGroupOf', 'IsDepiction',\n",
       "       'IsInside'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_files=[os.getcwd() + '/assets/open_sample.csv']\n",
    "\n",
    "df = pd.read_csv(annotation_files[0])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adding the file to the annotation set, remo automatically: \n",
    "- detects the class encoding and translates it into the corresponding labels\n",
    "- only adds annotations for classes that are part of the existing annotation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files_link_result': {'files uploaded': 0, 'annotations': 9, 'errors': []}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.add_data(local_files=annotation_files, annotation_task = 'Object detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AnnotationSet ID': 17,\n",
       "  'AnnotationSet name': 'Objects',\n",
       "  'n_images': 9,\n",
       "  'n_classes': 18,\n",
       "  'n_objects': 84,\n",
       "  'top_3_classes': [{'name': 'Fruit', 'count': 27},\n",
       "   {'name': 'Sports equipment', 'count': 12},\n",
       "   {'name': 'Mammal', 'count': 7}],\n",
       "  'creation_date': None,\n",
       "  'last_modified_date': '2020-03-08T16:35:05.643905Z'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.get_annotation_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/datasets/26\n"
     ]
    }
   ],
   "source": [
    "my_dataset.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_added_annotation.jpeg](assets/dataset_added_annotation.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations from code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see how we can add annotations to a specific image from code**\n",
    "\n",
    "This can be useful for instance to add model predictions as annotations or to tag specific images.\n",
    "\n",
    "First, let's retrieve one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 936 - 000a1249af2bc5f0.jpg\n",
      "Resoultion:  1024 x 678\n"
     ]
    }
   ],
   "source": [
    "images = my_dataset.images()\n",
    "my_image = images[1]\n",
    "print(my_image)\n",
    "print('Resoultion: ', my_image.width, 'x', my_image.height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we can add annotations using the Annotation class**\n",
    "\n",
    "We can add an annotation object to either the annotation set or directly to an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = remo.Annotation()\n",
    "annotation.add_item(classes=['Human hand'], bbox=[227, 284, 678, 674])\n",
    "annotation.add_item(classes=['Human hand'], bbox=[311, 193, 607, 526])\n",
    "\n",
    "annotation_set.add_annotation(my_image.id, annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = remo.Annotation()\n",
    "annotation.add_item(classes=['Fashion accessory'], bbox=[496, 322, 544,370])\n",
    "\n",
    "my_image.add_annotation(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/image/936?dataset_id=26\n"
     ]
    }
   ],
   "source": [
    "my_image.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![added_annotation.jpeg](assets/added_annotation.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Add annotations from custom file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
